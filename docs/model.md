# üß† OntoGen: Clasificaci√≥n Sem√°ntica de Productos via Traducci√≥n Autom√°tica

Este proyecto se inspira en el paper **"Don't Classify, Translate: Multi-Level E-Commerce Product Categorization via Machine Translation"** para implementar un sistema de clasificaci√≥n de productos basado en modelos de traducci√≥n autom√°tica como T5.

---

## ü§ñ Enfoque Tradicional vs. Enfoque de Traducci√≥n

### Clasificaci√≥n tradicional

* Enfocada en seleccionar una categor√≠a hoja (leaf node) a partir de un texto.
* Utiliza modelos de clasificaci√≥n (SVM, CNN, RNN).
* Limita la estructura del √°rbol: un solo camino de la ra√≠z a la hoja.
* No permite caminos alternativos ni adaptabilidad a nuevas categor√≠as.

### Nuestro enfoque

* Reformula el problema como una **tarea de traducci√≥n de texto**:

  * **Entrada:** Descripci√≥n del producto en lenguaje natural.
  * **Salida:** Secuencia de categor√≠as que forman una ruta desde la ra√≠z a la hoja.
* Utiliza modelos tipo Transformer (T5) para predecir esta secuencia.
* Permite generar rutas nuevas y convertir el √°rbol en un **grafo ac√≠clico dirigido (DAG)**.

---

## üîÑ Flujo del Sistema (Mermaid)

```mermaid
graph TD
    A[Descripci√≥n del producto] --> B[Preprocesamiento]
    B --> C[Modelo T5 Transformer]
    C --> D[Traducci√≥n a secuencia de categor√≠as]
    D --> E[Validaci√≥n de la ruta generada]
    E --> F[Salida: Ruta completa en taxonom√≠a]
```

---

## üìä Ventajas del Enfoque

* **Mejor rendimiento:** Supera m√©tricas de clasificadores tradicionales como DBN+KNN.
* **Adaptabilidad:** Genera rutas nuevas, lo que permite representar productos de forma m√°s flexible.
* **Robustez sem√°ntica:** Maneja errores, ambig√ºedades y variaciones en las descripciones.
* **Escalabilidad:** Reduce la necesidad de mantener m√∫ltiples clasificadores paso a paso.
* **Compatibilidad multiling√ºe:** Se adapta f√°cilmente a cat√°logos en varios idiomas.

---

## üìë Resultados del Paper

| Modelo                 | Dataset RDC    | Dataset Ichiba |
| ---------------------- | -------------- | -------------- |
| DBN+KNN (Clasificador) | 73.85 (F1)     | 82.05 (F1)     |
| Transformer (NMT)      | 73.83 (F1)     | **84.74 (F1)** |
| Seq2Seq+Transformer    | **74.19 (F1)** | **84.26 (F1)** |

* El modelo basado en traducci√≥n autom√°tica fue **consistentemente superior o igual**.
* Con menos datos de entrenamiento, **degrada menos su rendimiento**.
* **Crea nuevas rutas** que enriquecen la taxonom√≠a original.

---

## üîç Ejemplo de Traducci√≥n de Producto

**Input:** "Epson WorkForce Pro Inkjet Printer"

**Salida esperada:**

```
Electr√≥nica ‚Üí Impresi√≥n ‚Üí Impresoras
```

**Salida alternativa generada:**

```
Oficina ‚Üí Impresi√≥n ‚Üí Impresoras
```

Ambas son v√°lidas, mostrando la **capacidad del modelo para comprender el contexto** del producto.

---

## üìö Referencia

> Li, M.Y., Kok, S., & Tan, L. (2018). *Don‚Äôt Classify, Translate: Multi-Level E-Commerce Product Categorization via Machine Translation*. arXiv:1812.05774.

---

## ‚ú® Contribuciones futuras

* Integrar validaci√≥n estructural basada en SKOS/OWL.
* A√±adir soporte para categor√≠as regionales y multi-taxonom√≠as.
* Evaluar rutas generadas con usuarios reales mediante navegaci√≥n.
* Optimizar con fine-tuning de modelos como T5-small o mT5.

---

Este sistema permite transformar la clasificaci√≥n de productos en algo mucho m√°s natural, preciso y adaptable al contexto del e-commerce moderno.
